{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.api as sms\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "from statsmodels.stats.proportion import proportions_ztest, proportion_confint\n",
    "import scipy.stats\n",
    "import math\n",
    "booking = pd.read_csv(\"AB_test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group with Cindy, Linda, Fanbi, Yining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Variant', 'date', 'id', 'purchase_TF'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booking.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 users that appear multiple times in the dataset\n"
     ]
    }
   ],
   "source": [
    "session_counts = booking['id'].value_counts(ascending=False)\n",
    "multi_users = session_counts[session_counts > 1].count()\n",
    "print(f'There are {multi_users} users that appear multiple times in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Conduct an A/B test to determine whether Alternative B improved conversion rates (site users book the property) over alternative A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into group A and group B\n",
    "control = booking.loc[booking[\"Variant\"] == \"A\"]\n",
    "treat = booking.loc[booking[\"Variant\"] == \"B\"]\n",
    "\n",
    "# \n",
    "control_true = control[\"purchase_TF\"] == True\n",
    "treat_true = treat[\"purchase_TF\"] == True\n",
    "\n",
    "# number of control = true and treat = true\n",
    "n_control_true = sum(control_true)\n",
    "n_treat_true = sum(treat_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_control = control_true.count()\n",
    "n_treat = treat_true.count()\n",
    "successes = [n_control_true, n_treat_true]\n",
    "nobs = [n_control, n_treat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.0000000845\n"
     ]
    }
   ],
   "source": [
    "z_stat, pval = proportions_ztest(successes, nobs=nobs,alternative=\"smaller\")\n",
    "print(f'p-value: {pval:.10f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The p-value is 0.0000000845. At alpha level = 0.05, we reject null hypothesis. We cconclude that alternative B improved conversion rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculate the optimal sample size for a 95% confidence rate and test with 80% power. Conduct the test 10 times using samples of the optimal size. Report results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle n = (t_{\\alpha/2} * \\sqrt{2p(p-1)} + t_{\\beta} * \\sqrt{p_{0}(1-p_{0}) + p_{1}(1-p_{1})})^2 * 1/{\\delta}^2 $"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "display(Math( r'n = (t_{\\alpha/2} * \\sqrt{2p(p-1)} + t_{\\beta} * \\sqrt{p_{0}(1-p_{0}) + p_{1}(1-p_{1})})^2 * 1/{\\delta}^2 '  ))\n",
    "#display(Math(r'n=\\frac{2 * p * (1 - p) * (Z_{\\alpha / 2} + Z_{\\beta})^2}{(p_B + p_a)^2}'))\n",
    "             \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_a_2 = scipy.stats.t.ppf(q=.05/2,df=(booking.shape[0]-1))\n",
    "t_b = scipy.stats.t.ppf(q=0.2,df=(booking.shape[0]-1))\n",
    "#1- Î² is the selected power (0.8)\n",
    "\n",
    "p0 = n_control_true / control.shape[0]\n",
    "p1 = n_treat_true / treat.shape[0]\n",
    "p = (p0+p1)/2 # https://www.nber.org/system/files/working_papers/w15701/w15701.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimial size of each group is 2941.7255370018324\n"
     ]
    }
   ],
   "source": [
    "optimal_size = ( -t_a_2 * ( 2 * p * (1-p) )**0.5 + ( -t_b * ( p0 * (1-p0) + p1 * (1-p1) )** 0.5 ) )**2 * (1 / (p0-p1)**2)\n",
    "# delta = p0-p1\n",
    "print(\"The optimial size of each group is\",optimal_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/the-math-behind-a-b-testing-with-example-code-part-1-of-2-7be752e1d06f\n",
    "# minimum size\n",
    "#optimal_size = 2*p*(1-p)*(t_a_2+t_b)**2/(p1-p0)**2\n",
    "#print(\"The optimial size of each group is\",optimal_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sdt = (p*(1-p)/booking.shape[0])**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02947087793433457\n",
      "0.012811800827857371\n",
      "0.013434916142272994\n",
      "0.01974712246575\n",
      "0.017143336250841672\n",
      "0.06013882864599316\n",
      "0.00019577907377768831\n",
      "0.01594092779335723\n",
      "1.9248012988440275e-05\n",
      "0.00013817198905973678\n"
     ]
    }
   ],
   "source": [
    "# Randomly sample 2943 samples in each group\n",
    "from random import sample\n",
    "import numpy as np\n",
    "\n",
    "for i in range(10,20):\n",
    "\n",
    "    control_opt = control.sample( int(np.ceil(optimal_size)),random_state=i ) #np.ceilwill round up the number\n",
    "    treat_opt = treat.sample( int(np.ceil(optimal_size)),random_state=i ) \n",
    "    \n",
    "    control_opt_true = control_opt[\"purchase_TF\"] == True\n",
    "    treat_opt_true = treat_opt[\"purchase_TF\"] == True\n",
    "    \n",
    "    n_control_opt_true = sum(control_opt_true)\n",
    "    n_treat_opt_true = sum(treat_opt_true)\n",
    "    \n",
    "    successes = [n_control_opt_true, n_treat_opt_true]\n",
    "    pval = proportions_ztest(successes, nobs = int(np.ceil(optimal_size))*2,alternative=\"smaller\")[1]\n",
    "    print(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Conduct a sequential test for the 10 samples. For any of the samples, were you able to stop the test prior to using the full sample? What was the average number of iterations required to stop the test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1028\n",
      "3.096407695880565\n",
      "673\n",
      "3.0561548035561894\n",
      "199\n",
      "3.09000194212208\n",
      "272\n",
      "-1.6406831169556917\n",
      "1441\n",
      "3.0489488373609697\n",
      "1495\n",
      "3.0902206978748916\n",
      "679\n",
      "3.0607405658355105\n",
      "286\n",
      "3.057464905514156\n",
      "500\n",
      "3.088982973932549\n",
      "398\n",
      "3.0110250151840394\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a_bound = math.log(1/0.05)\n",
    "b_bound = math.log(0.2)\n",
    "\n",
    "boundary_test = 0\n",
    "iteration = 0\n",
    "p0 = n_control_true / control.shape[0]\n",
    "p1 = n_treat_true / treat.shape[0]\n",
    "sum_iter = 0\n",
    "\n",
    "for i in range(10,20):\n",
    "    boundary_test = 0\n",
    "    iteration = 0\n",
    "    for j in range( int(np.ceil(optimal_size)) ):\n",
    "        sample = treat.sample( int(np.ceil(optimal_size)),random_state=i ).reset_index()\n",
    "        if sample.loc[j,\"purchase_TF\"] == True:\n",
    "            boundary_test = boundary_test + math.log(p1/p0)\n",
    "            iteration = iteration + 1\n",
    "            #print(boundary_test)\n",
    "        else:\n",
    "            boundary_test = boundary_test + math.log((1-p1)/(1-p0))\n",
    "            iteration = iteration + 1\n",
    "            #print(boundary_test)\n",
    "        if boundary_test >=  a_bound or boundary_test <= b_bound:\n",
    "            break\n",
    "    sum_iter = sum_iter + iteration\n",
    "    print(iteration)\n",
    "    print(boundary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697.1\n"
     ]
    }
   ],
   "source": [
    "# Average iteration\n",
    "print(sum_iter/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: On Average, it requires 698 (697.1) iterations to stop the test. In our 10 samples, the test stops prior to using the full sample. 9 out of 10 trials reached the upper boundary, and we would like to accept H1 and reject the Ho. In only 1 sample, we failed to reject Ho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
